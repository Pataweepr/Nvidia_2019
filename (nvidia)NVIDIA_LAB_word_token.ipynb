{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(nvidia)NVIDIA_LAB_word_token.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pataweepr/Nvidia_2019/blob/master/(nvidia)NVIDIA_LAB_word_token.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hctJ61HmCjJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.0.0a0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB076rQ_C5Bh",
        "colab_type": "code",
        "outputId": "86c60a7e-7024-4faf-92f7-0484e65c43c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKBssDgiECzJ",
        "colab_type": "text"
      },
      "source": [
        "## Setting up to use the gpu  \n",
        "\n",
        "Before we start, we need to change the environment of Colab to use GPU. Do so by:\n",
        "\n",
        "Runtime -> Change runtime type -> Hardware accelerator -> GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teiwAR57ENeK",
        "colab_type": "code",
        "outputId": "d6db70b3-2eb3-4e6e-d6f7-67b3cd040b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "## check gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 21 10:47:13 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8nPVt1CNTzL",
        "colab_type": "code",
        "outputId": "0c64bac1-e9be-472e-b0a8-0d8ff54f0407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGL_Pe5VIO8p",
        "colab_type": "text"
      },
      "source": [
        "###[FILE](https://drive.google.com/file/d/1iodAqVNWEkiJgH8cWkccsLi_tqoFcMrV/view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xID-GrB4IuxA",
        "colab_type": "code",
        "outputId": "a2d85e2c-7d53-49fa-8f59-ccad0e391a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "!tar -xvzf gdrive/My\\ Drive/corpora.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpora/\n",
            "corpora/mnist_data/\n",
            "corpora/mnist_data/t10k-images-idx3-ubyte.gz\n",
            "corpora/mnist_data/train-images-idx3-ubyte.gz\n",
            "corpora/mnist_data/.ipynb_checkpoints/\n",
            "corpora/mnist_data/vis_utils.py\n",
            "corpora/mnist_data/__init__.py\n",
            "corpora/mnist_data/load_mnist.py\n",
            "corpora/mnist_data/train-labels-idx1-ubyte.gz\n",
            "corpora/mnist_data/t10k-labels-idx1-ubyte.gz\n",
            "corpora/BEST/\n",
            "corpora/BEST/test/\n",
            "corpora/BEST/test/df_best_article_test.csv\n",
            "corpora/BEST/test/df_best_encyclopedia_test.csv\n",
            "corpora/BEST/test/df_best_novel_test.csv\n",
            "corpora/BEST/test/df_best_news_test.csv\n",
            "corpora/BEST/train/\n",
            "corpora/BEST/train/df_best_encyclopedia_train.csv\n",
            "corpora/BEST/train/df_best_article_train.csv\n",
            "corpora/BEST/train/df_best_news_train.csv\n",
            "corpora/BEST/train/df_best_novel_train.csv\n",
            "corpora/BEST/val/\n",
            "corpora/BEST/val/df_best_encyclopedia_val.csv\n",
            "corpora/BEST/val/df_best_news_val.csv\n",
            "corpora/BEST/val/df_best_article_val.csv\n",
            "corpora/BEST/val/df_best_novel_val.csv\n",
            "corpora/.ipynb_checkpoints/\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer.new-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/BackProp-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer_backup-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/char2vec-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer-checkpoint.ipynb\n",
            "corpora/cattern/\n",
            "corpora/cattern/gradient_check.py\n",
            "corpora/cattern/.ipynb_checkpoints/\n",
            "corpora/cattern/__init__.py\n",
            "corpora/cattern/data_utils.py\n",
            "corpora/wiki/\n",
            "corpora/wiki/thwiki_chk.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRWiw3pNImP1",
        "colab_type": "code",
        "outputId": "7fedb097-2da1-424e-b4b5-2362c50c8f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-21 10:47:55--  https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548640 (1.5M) [text/plain]\n",
            "Saving to: ‘words_th.txt’\n",
            "\n",
            "\rwords_th.txt          0%[                    ]       0  --.-KB/s               \rwords_th.txt        100%[===================>]   1.48M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-08-21 10:47:55 (20.8 MB/s) - ‘words_th.txt’ saved [1548640/1548640]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aygu3JGqJBkP",
        "colab_type": "code",
        "outputId": "d4dd51b0-0567-4493-d4d4-44a1351252d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls corpora/BEST/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTqtPrUuINvK",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNLQWSLBGNVs",
        "colab_type": "text"
      },
      "source": [
        "## Word Tokenizer exercise##\n",
        "\n",
        "In this exercise, you are going to build a set of deep learning models on a (sort of) real world task using Tensorflow and Keras. Tensorflow is a deep learning framwork developed by Google, and Keras is a frontend library built on top of Tensorflow (or Theano, CNTK) to provide an easier way to use standard layers and networks.\n",
        "\n",
        "To complete this exercise, you will need to build deep learning models for word tokenization in Thai (แบ่งเว้นวรรคภาษาไทย) using NECTEC's BEST corpus. You will build one model for each of the following type:\n",
        "- Fully Connected (Feedforward) Neural Network\n",
        "- One-Dimentional Convolution Neural Network (1D-CNN)\n",
        "- Recurrent Neural Network with Gated Recurrent Unit (GRU)\n",
        "\n",
        "and one more model of your choice to achieve the highest score possible.\n",
        "\n",
        "We provide the code for data cleaning and some starter code for keras in this notebook but feel free to modify those parts to suit your needs. You can also complete this exercise using only Tensorflow (without using Keras). Feel free to use additional libraries (e.g. scikit-learn) as long as you have a model for each type mentioned above.\n",
        "\n",
        "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on GCloud using the provided disk image you are all set.\n",
        "\n",
        "As a reminder,\n",
        "\n",
        "### Don't forget to shut down your instance on Gcloud when you are not using it ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K5kBrJHQkRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run setup code\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QueOi5QAUER",
        "colab_type": "code",
        "outputId": "7dd02d38-384b-400a-f947-b5e5d022afd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('\\ufeff')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdDJ3GfXEPPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a character map\n",
        "CHARS = [\n",
        "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
        "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
        "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
        "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
        "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
        "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
        "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
        "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
        "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
        "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
        "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
        "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
        "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
        "]\n",
        "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5nfX2BTGiP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_n_gram_df(df, n_pad):\n",
        "  \"\"\"\n",
        "  Given an input dataframe, create a feature dataframe of shifted characters\n",
        "  Input:\n",
        "  df: timeseries of size (N)\n",
        "  n_pad: the number of context. For a given character at position [idx],\n",
        "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
        "    as features for that character.\n",
        "  \n",
        "  Output:\n",
        "  dataframe of size (N * n_pad) which each row contains the character, \n",
        "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
        "    of that character.\n",
        "  \"\"\"\n",
        "  n_pad_2 = int((n_pad - 1)/2)\n",
        "  for i in range(n_pad_2):\n",
        "      df['char-{}'.format(i+1)] = df['char'].shift(i + 1)\n",
        "      df['char{}'.format(i+1)] = df['char'].shift(-i - 1)\n",
        "  return df[n_pad_2: -n_pad_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u_vSQFiG3U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_feature(best_processed_path, option='train'):\n",
        "  \"\"\"\n",
        "  Transform the path to a directory containing processed files \n",
        "  into a feature matrix and output array\n",
        "  Input:\n",
        "  best_processed_path: str, path to a processed version of the BEST dataset\n",
        "  option: str, 'train' or 'test'\n",
        "  \"\"\"\n",
        "  # we use padding equals 21 here to consider 10 characters to the left\n",
        "  # and 10 characters to the right as features for the character in the middle\n",
        "  n_pad = 21\n",
        "  n_pad_2 = int((n_pad - 1)/2)\n",
        "  pad = [{'char': ' ', 'target': True}]\n",
        "  df_pad = pd.DataFrame(pad * n_pad_2)\n",
        "\n",
        "  df = []\n",
        "  # article types in BEST corpus\n",
        "  article_types = ['article', 'encyclopedia', 'news', 'novel']\n",
        "  for article_type in article_types:\n",
        "      df.append(pd.read_csv(os.path.join(best_processed_path, option, 'df_best_{}_{}.csv'.format(article_type, option))))\n",
        "  \n",
        "  df = pd.concat(df)\n",
        "  # pad with empty string feature\n",
        "  df = pd.concat((df_pad, df, df_pad))\n",
        "\n",
        "  # map characters to numbers, use 'other' if not in the predefined character set.\n",
        "  df['char'] = df['char'].map(lambda x: CHARS_MAP.get(x, 80))\n",
        "\n",
        "  # Use nearby characters as features\n",
        "  df_with_context = create_n_gram_df(df, n_pad=n_pad)\n",
        "\n",
        "  char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
        "             ['char-' + str(i + 1) for i in range(n_pad_2)] + ['char']\n",
        "\n",
        "  # convert pandas dataframe to numpy array to feed to the model\n",
        "  x_char = df_with_context[char_row].as_matrix()\n",
        "  y = df_with_context['target'].astype(int).as_matrix()\n",
        "\n",
        "  return x_char, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV7_tlICG5t7",
        "colab_type": "code",
        "outputId": "f181d766-db12-4cf0-d004-1fbbcacadd92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Path to the preprocessed data\n",
        "best_processed_path = 'corpora/BEST'\n",
        "\n",
        "# Load preprocessed BEST corpus\n",
        "x_train_char, y_train = prepare_feature(best_processed_path, option='train')\n",
        "x_val_char, y_val = prepare_feature(best_processed_path, option='val')\n",
        "x_test_char, y_test = prepare_feature(best_processed_path, option='test')\n",
        "\n",
        "# As a sanity check, we print out the size of the training, val, and test data.\n",
        "print('Training data shape: ', x_train_char.shape)\n",
        "print('Training data labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', x_val_char.shape)\n",
        "print('Validation data labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', x_test_char.shape)\n",
        "print('Test data labels shape: ', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (16461637, 21)\n",
            "Training data labels shape:  (16461637,)\n",
            "Validation data shape:  (2035694, 21)\n",
            "Validation data labels shape:  (2035694,)\n",
            "Test data shape:  (2271932, 21)\n",
            "Test data labels shape:  (2271932,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAGZtQmla9fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def get_feedforward_nn():\n",
        "  input1 = Input(shape=(21,))\n",
        "  x = Dense(100, activation='relu')(input1)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=input1, outputs=out)\n",
        "  model.compile(optimizer=Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJA84w3zbxxQ",
        "colab_type": "code",
        "outputId": "6a29f0df-b4b1-4e72-d2a3-f0f6dbf2d413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "#from keras import backend as K\n",
        "#K.clear_session()\n",
        "\n",
        "# Path to save model parameters\n",
        "weight_path_feedforward_nn='/data/model_weight_feedforward_nn.h5'\n",
        "\n",
        "# Training callbacks list. TensorBoard() write logs for tensorboard GUI. \n",
        "# ModelCheckpoint() writes the resulting model.\n",
        "# Note that writing to disk takes time (longer than model training time). \n",
        "# For other sections, you might not writing any files to disk \n",
        "# or write only the graph for TensorBoard.\n",
        "callbacks_list_feedforward_nn = [\n",
        "        TensorBoard(log_dir='/data/Graph/ff', histogram_freq=1, write_graph=True, write_grads=False),\n",
        "        ModelCheckpoint(\n",
        "            weight_path_feedforward_nn,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        )\n",
        "  ]\n",
        "\n",
        "print('start training')\n",
        "verbose = 1\n",
        "model_feedforward_nn = get_feedforward_nn()\n",
        "train_params = [(3, 512)]\n",
        "for (epochs, batch_size) in train_params:\n",
        "  print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "  model_feedforward_nn.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                           callbacks=callbacks_list_feedforward_nn,\n",
        "                           validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 10:48:27.152774 140698820360064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0821 10:48:27.246139 140698820360064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "train with 3 epochs and 512 batch size\n",
            "Train on 16461637 samples, validate on 2035694 samples\n",
            "Epoch 1/3\n",
            "16459776/16461637 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8500\n",
            "Epoch 00001: val_loss improved from inf to 0.29131, saving model to /data/model_weight_feedforward_nn.h5\n",
            "16461637/16461637 [==============================] - 136s 8us/sample - loss: 0.3464 - acc: 0.8500 - val_loss: 0.2913 - val_acc: 0.8744\n",
            "Epoch 2/3\n",
            "16458240/16461637 [============================>.] - ETA: 0s - loss: 0.2705 - acc: 0.8855\n",
            "Epoch 00002: val_loss improved from 0.29131 to 0.25171, saving model to /data/model_weight_feedforward_nn.h5\n",
            "16461637/16461637 [==============================] - 135s 8us/sample - loss: 0.2705 - acc: 0.8855 - val_loss: 0.2517 - val_acc: 0.8945\n",
            "Epoch 3/3\n",
            "16457216/16461637 [============================>.] - ETA: 0s - loss: 0.2480 - acc: 0.8965\n",
            "Epoch 00003: val_loss improved from 0.25171 to 0.23989, saving model to /data/model_weight_feedforward_nn.h5\n",
            "16461637/16461637 [==============================] - 132s 8us/sample - loss: 0.2480 - acc: 0.8965 - val_loss: 0.2399 - val_acc: 0.9017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cneHmvi_cCnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "\n",
        "################################################################################\n",
        "# Write a function to evaluate your model. Your function must make prediction  #\n",
        "# using the input model and return f-score, precision, and recall of the model.#\n",
        "# You can make predictions by calling model.predict().                         #\n",
        "################################################################################\n",
        "def evaluate(x_test, y_test, model):\n",
        "  \"\"\"\n",
        "  Evaluate model on the splitted 10 percent testing set.\n",
        "  \"\"\"\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  #map probability to class\n",
        "  prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
        "  y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
        "    \n",
        "  f1score = f1_score(y_test,y_pred)\n",
        "  precision = precision_score(y_test,y_pred)\n",
        "  recall = recall_score(y_test,y_pred)\n",
        "  return f1score, precision, recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh3QMrzZcNRE",
        "colab_type": "code",
        "outputId": "be905bae-76af-4159-f5da-6cf930c60d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluate(x_test_char, y_test, model_feedforward_nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8237192600033347, 0.8490107642265518, 0.7998910030092647)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrptrB2M-ozu",
        "colab_type": "code",
        "outputId": "a44b8e00-0d74-4281-f3c0-d89ea9e42082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#print char of feature 1\n",
        "char = np.array(CHARS)\n",
        "\n",
        "#A function for displaying our features in text\n",
        "def print_features(tfeature,label,index):\n",
        "    feature = np.array(tfeature[index],dtype=int).reshape(21,1)\n",
        "    #Convert to string\n",
        "    char_list = char[feature]\n",
        "    left = ''.join(reversed(char_list[10:20].reshape(10))).replace(\" \", \"\")\n",
        "    center = ''.join(char_list[20])\n",
        "    right =  ''.join(char_list[0:10].reshape(10)).replace(\" \", \"\")\n",
        "    word = ''.join([left,' ',center,' ',right])\n",
        "    print(center + ': ' + word + \"\\tpred = \"+str(label[index]))\n",
        "\n",
        "for ind in range(0,30):\n",
        "    print_features(x_train_char,y_train,ind)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ค:  ค ณะตุลาการร\tpred = 1\n",
            "ณ: ค ณ ะตุลาการรั\tpred = 0\n",
            "ะ: คณ ะ ตุลาการรัฐ\tpred = 0\n",
            "ต: คณะ ต ุลาการรัฐธ\tpred = 0\n",
            "ุ: คณะต ุ ลาการรัฐธร\tpred = 0\n",
            "ล: คณะตุ ล าการรัฐธรร\tpred = 0\n",
            "า: คณะตุล า การรัฐธรรม\tpred = 0\n",
            "ก: คณะตุลา ก ารรัฐธรรมน\tpred = 0\n",
            "า: คณะตุลาก า รรัฐธรรมนู\tpred = 0\n",
            "ร: คณะตุลากา ร รัฐธรรมนูญ\tpred = 0\n",
            "ร: คณะตุลาการ ร ัฐธรรมนูญก\tpred = 0\n",
            "ั: ณะตุลาการร ั ฐธรรมนูญกั\tpred = 0\n",
            "ฐ: ะตุลาการรั ฐ ธรรมนูญกับ\tpred = 0\n",
            "ธ: ตุลาการรัฐ ธ รรมนูญกับค\tpred = 0\n",
            "ร: ุลาการรัฐธ ร รมนูญกับคว\tpred = 0\n",
            "ร: ลาการรัฐธร ร มนูญกับควา\tpred = 0\n",
            "ม: าการรัฐธรร ม นูญกับความ\tpred = 0\n",
            "น: การรัฐธรรม น ูญกับความเ\tpred = 0\n",
            "ู: ารรัฐธรรมน ู ญกับความเป\tpred = 0\n",
            "ญ: รรัฐธรรมนู ญ กับความเป็\tpred = 0\n",
            "ก: รัฐธรรมนูญ ก ับความเป็น\tpred = 1\n",
            "ั: ัฐธรรมนูญก ั บความเป็นอ\tpred = 0\n",
            "บ: ฐธรรมนูญกั บ ความเป็นอง\tpred = 0\n",
            "ค: ธรรมนูญกับ ค วามเป็นองค\tpred = 1\n",
            "ว: รรมนูญกับค ว ามเป็นองค์\tpred = 0\n",
            "า: รมนูญกับคว า มเป็นองค์ก\tpred = 0\n",
            "ม: มนูญกับควา ม เป็นองค์กร\tpred = 0\n",
            "เ: นูญกับความ เ ป็นองค์กรต\tpred = 1\n",
            "ป: ูญกับความเ ป ็นองค์กรตุ\tpred = 0\n",
            "็: ญกับความเป ็ นองค์กรตุล\tpred = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDIpRiUJ-r08",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qVB72153tsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO#4\n",
        "# Write a function that return feedforward model with dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def get_nn_with_dropout():\n",
        "    input1 = Input(shape=(21,))\n",
        "    x = Dense(100, activation='relu')(input1)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input1, outputs=out)\n",
        "    model.compile(optimizer=Adam(0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbzOHhQW32rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('start training')\n",
        "verbose = 2\n",
        "model_nn_with_dropout = get_nn_with_dropout()\n",
        "# TODO#5\n",
        "# Complete the code to train your model with dropout\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Path to save model parameters\n",
        "weight_path_nn_with_dropout='/data/model_weight_nn_with_dropout.h5'\n",
        "\n",
        "# Training callbacks list. TensorBoard() write logs for tensorboard GUI. \n",
        "# ModelCheckpoint() writes the resulting model.\n",
        "# Note that writing to disk takes time (longer than model training time). \n",
        "# For other sections, you might not writing any files to disk \n",
        "# or write only the graph for TensorBoard.\n",
        "callbacks_list_feedforward_nn = [\n",
        "        TensorBoard(log_dir='/data/Graph/ffdropout', histogram_freq=1, write_graph=True, write_grads=False),\n",
        "        ModelCheckpoint(\n",
        "            weight_path_nn_with_dropout,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        )\n",
        "  ]\n",
        "\n",
        "print('start training')\n",
        "verbose = 1\n",
        "train_params = [(3, 512)]\n",
        "for (epochs, batch_size) in train_params:\n",
        "    print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "    model_nn_with_dropout.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                           callbacks=callbacks_list_feedforward_nn,\n",
        "                           validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILEknJz739TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(x_test_char, y_test, model_nn_with_dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy39pHHz3_FS",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzfRybFzFasb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#6:                                                                      #\n",
        "# Write a function that returns keras convolution nueral network model.        #\n",
        "# You can choose any normalization methods, activation function, as well as    #\n",
        "# any hyperparameter the way you want. Your goal is to predict a score         #\n",
        "# between [0,1] for each input whether it is the beginning of the word or not. #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Conv1D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import tensorflow as tf\n",
        "def get_conv1d_nn():\n",
        "    input1 = Input(shape=(21,))\n",
        "    x = Embedding(len(CHARS), 32, input_length=21)(input1)\n",
        "    x = Conv1D(100,5, activation='relu',input_shape=(21, 32))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input1, outputs=out)\n",
        "    model.compile(optimizer=Adam(0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "#from tensorflow.keras import backend as K\n",
        "#K.clear_session()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqy0Df8BgLlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ################################################################################\n",
        "# TODO#7:                                                                      #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "################################################################################\n",
        "print('start training conv1d')\n",
        "model_conv1d_nn = get_conv1d_nn()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "#K.clear_session()\n",
        "train_params = [(3, 512)]\n",
        "for (epochs, batch_size) in train_params:\n",
        "    print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "    model_conv1d_nn.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=1,\n",
        "                           callbacks=callbacks_list_feedforward_nn,\n",
        "                           validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6YM6dAa4Z-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(x_test_char, y_test, model_conv1d_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhV51Q9D4gZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWICXg364git",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "################################################################################\n",
        "# TODO#8                                                                       #\n",
        "# Write a function that returns keras GRU network moded. You can choose any    #\n",
        "# normalization methods, activation function, as well as any hyperparameter    #\n",
        "# the way you want. Your goal is to predict a score between [0,1] for each     #\n",
        "# input whether it is the beginning of the word or not.                        #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "\n",
        "def get_gru():\n",
        "    input1 = Input(shape=(21,))\n",
        "    x = Embedding(len(CHARS), 32, input_length=21)(input1)\n",
        "    x = Bidirectional(GRU(32,return_sequences = True))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    model = Model(inputs=input1, outputs=out)\n",
        "    model.compile(optimizer=Adam(0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqumbhuf4i7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train_char.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CINwBg44lgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#9                                                                       #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "################################################################################\n",
        "print('start training conv1d')\n",
        "model_gru = get_gru()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "for (epochs, batch_size) in train_params:\n",
        "    print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "    model_gru.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=1,\n",
        "                           callbacks=callbacks_list_feedforward_nn,\n",
        "                           validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9XDsY0L4nn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(x_test_char, y_test, model_gru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-mgcWEaHnD-",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_RIQK3cWrp",
        "colab_type": "code",
        "outputId": "f2fa5ac6-23d0-4b28-a555-0f1160b92e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpora  gdrive  sample_data  words_th.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ZHGhYicUyM",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhiDwZjOJdfW",
        "colab_type": "text"
      },
      "source": [
        "# pythaiNLP (mm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVouG8DgHoS5",
        "colab_type": "code",
        "outputId": "f631a6bc-d1c5-44ff-94da-b1b5c3867dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.6/dist-packages (2.0.7)\n",
            "Requirement already satisfied: nltk>=3.2.2 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.28.1)\n",
            "Requirement already satisfied: tinydb in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.13.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2018.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.21.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.0)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.7.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.2->pythainlp) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26EtD9EzJpUs",
        "colab_type": "code",
        "outputId": "bf740dd3-b3d4-4093-c0f4-f1e16ced5416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "text='ผมรักคุณนะครับโอเคบ่พวกเราเป็นคนไทยรักภาษาไทยภาษาบ้านเกิด'\n",
        "c=word_tokenize(text,engine='newmm')\n",
        "print(c)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ผม', 'รัก', 'คุณ', 'นะ', 'ครับ', 'โอเค', 'บ่', 'พวกเรา', 'เป็น', 'คนไทย', 'รัก', 'ภาษาไทย', 'ภาษา', 'บ้านเกิด']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PulBeQJU9iis",
        "colab_type": "code",
        "outputId": "7bd8fe6d-0142-4843-fdfc-14b9610d1280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!ls /usr/local/lib/python3.6/dist-packages/pythainlp/corpus/"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "common.py\t       thailand_provinces_th.txt\n",
            "conceptnet.py\t       tha-wn.db\n",
            "corpus_license.md      tnc_freq.txt\n",
            "countries_th.txt       tnc.py\n",
            "__init__.py\t       ttc_freq.txt\n",
            "negations_th.txt       ttc.py\n",
            "orchid_pos_th.json     ud_thai_pud_pt_tagger.dill\n",
            "orchid_pt_tagger.dill  ud_thai_pud_unigram_tagger.dill\n",
            "__pycache__\t       wordnet.py\n",
            "stopwords_th.txt       words_th_frozen_201810.txt\n",
            "syllables_th.txt       words_th.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WrGL-ST-IQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"สามย่านมิตรทาวน์\" >> words_th.txt\n",
        "!cp /usr/local/lib/python3.6/dist-packages/pythainlp/corpus/words_th.txt ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiKNb6XPa6gw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa6efa7b-8f8c-4b8c-c56d-60594e0c674c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  words_th_frozen_201810.txt  words_th.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf9P1uWH-8ZI",
        "colab_type": "code",
        "outputId": "a342b356-d046-4ba9-bb1b-6c8a8bf258d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n",
        "c=word_tokenize(text,engine='newmm')\n",
        "print(c)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh-412pga9et",
        "colab_type": "text"
      },
      "source": [
        "ใช้ from marisa_trie import Trie และ ใช้ function corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLVLkOtP_MAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bc28cc7-3f83-457a-fccd-e9e80d3cdb96"
      },
      "source": [
        "from pythainlp.corpus import get_corpus\n",
        "from marisa_trie import Trie\n",
        "\n",
        "text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n",
        "new_tokenizer = Trie(get_corpus('words_th.txt'))\n",
        "\n",
        "tokens = word_tokenize(text, custom_dict=truevoice_dict, engine='newmm')\n",
        "print(tokens)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่านมิตรทาวน์']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrThPT1aUXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}